{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "693c84f9",
   "metadata": {},
   "source": [
    "# Artefactual Package Demo: Hallucination Detection\n",
    "\n",
    "This notebook demonstrates the `artefactual` package for scoring LLM outputs, specifically focusing on hallucination detection using entropy-based methods.\n",
    "\n",
    "We explore two examples:\n",
    "1.  **General Knowledge Question**: Asking for the capital of France (expected high certainty/low entropy).\n",
    "2.  **Hallucination Trigger**: Asking about the first author of our paper (Charles Moslonka) to observe how the model hallucinates biographical details (expected higher entropy/uncertainty).\n",
    "\n",
    "We will use:\n",
    "*   `vLLM` for efficient inference with the `Falcon3-10B-Instruct` model.\n",
    "*   `WEPR` (Weighted EPR) scorer from the `artefactual` package to quantify the uncertainty of the generated sequences.\n",
    "*   Visualizations to inspect token-level scores, highlighting potentially hallucinated segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82e2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from pprint import pprint\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "from artefactual.preprocessing import parse_model_outputs\n",
    "from artefactual.scoring import WEPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71467ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT = \"tiiuae/Falcon3-10B-Instruct\"\n",
    "\n",
    "llm = LLM(\n",
    "    model=MODEL_CHECKPOINT,\n",
    "    tensor_parallel_size=2)  # adjust based on your hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "71bb1aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference with vLLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 619.09it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, est. speed input: 67.54 toks/s, output: 46.75 toks/s]\n",
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 483.16it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s, est. speed input: 39.87 toks/s, output: 51.82 toks/s]\n"
     ]
    }
   ],
   "source": [
    "prompt1 = [\"What is the capital city of France ? Please answer briefly.\"]\n",
    "\n",
    "prompt2 = [\"Who is Charles Moslonka ? Where was he born ? Please answer in two sentences.\"]\n",
    "\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.7, top_p=1, logprobs=15, max_tokens=2000, top_k=50)\n",
    "print(\"Running inference with vLLM...\")  # noqa: T201\n",
    "outputs1 = llm.generate(prompt1, sampling_params)\n",
    "outputs2 = llm.generate(prompt2, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "09c02d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1 generated sequence :\n",
      "\n",
      "<|assistant|>\n",
      "Paris.\n",
      "\n",
      "**** Output 1 Tokens and Logprobs ****\n",
      "\n",
      "'Token ID: 12, Decoded_token: \\n'\n",
      "'Token ID: 2051, Decoded_token: <'\n",
      "'Token ID: 2115, Decoded_token: |'\n",
      "'Token ID: 91961, Decoded_token: assistant'\n",
      "'Token ID: 100846, Decoded_token: |>'\n",
      "'Token ID: 12, Decoded_token: \\n'\n",
      "'Token ID: 41308, Decoded_token: Paris'\n",
      "'Token ID: 2037, Decoded_token: .'\n",
      "'Token ID: 11, Decoded_token: <|endoftext|>'\n",
      "\n",
      "\n",
      "\n",
      "Output 2 generated sequence :\n",
      "\n",
      "<|assistant|>\n",
      "Charles Moslonka is a South African writer and journalist. He was born in Cape Town.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "**** Output 2 Tokens and Logprobs ****\n",
      "\n",
      "\n",
      "'Token ID: 12, Decoded_token: \\n'\n",
      "'Token ID: 2051, Decoded_token: <'\n",
      "'Token ID: 2115, Decoded_token: |'\n",
      "'Token ID: 91961, Decoded_token: assistant'\n",
      "'Token ID: 100846, Decoded_token: |>'\n",
      "'Token ID: 12, Decoded_token: \\n'\n",
      "'Token ID: 33350, Decoded_token: Charles'\n",
      "'Token ID: 20109, Decoded_token:  Mos'\n",
      "'Token ID: 15465, Decoded_token: lon'\n",
      "'Token ID: 7406, Decoded_token: ka'\n",
      "'Token ID: 2340, Decoded_token:  is'\n",
      "'Token ID: 2265, Decoded_token:  a'\n",
      "'Token ID: 4960, Decoded_token:  South'\n",
      "'Token ID: 8906, Decoded_token:  African'\n",
      "'Token ID: 8211, Decoded_token:  writer'\n",
      "'Token ID: 2305, Decoded_token:  and'\n",
      "'Token ID: 18363, Decoded_token:  journalist'\n",
      "'Token ID: 2037, Decoded_token: .'\n",
      "'Token ID: 2768, Decoded_token:  He'\n",
      "'Token ID: 2440, Decoded_token:  was'\n",
      "'Token ID: 7078, Decoded_token:  born'\n",
      "'Token ID: 2303, Decoded_token:  in'\n",
      "'Token ID: 17427, Decoded_token:  Cape'\n",
      "'Token ID: 9485, Decoded_token:  Town'\n",
      "'Token ID: 2037, Decoded_token: .'\n",
      "'Token ID: 11, Decoded_token: <|endoftext|>'\n"
     ]
    }
   ],
   "source": [
    "seq_len_1 = len(outputs1[0].outputs[0].logprobs)\n",
    "token_ids_1 = outputs1[0].outputs[0].token_ids\n",
    "\n",
    "seq_len_2 = len(outputs2[0].outputs[0].logprobs)\n",
    "token_ids_2 = outputs2[0].outputs[0].token_ids\n",
    "\n",
    "print(f\"Output 1 generated sequence :\\n{outputs1[0].outputs[0].text}\")  # noqa: T201\n",
    "\n",
    "print(\"\"\"\n",
    "**** Output 1 Tokens and Logprobs ****\n",
    "\"\"\")  # noqa: T201\n",
    "\n",
    "for i in range(seq_len_1):\n",
    "    pprint(f\"Token ID: {token_ids_1[i]}, Decoded_token: {outputs1[0].outputs[0].logprobs[i][token_ids_1[i]].decoded_token}\")  # noqa: T201\n",
    "list_of_sampled_tokens_1 = [outputs1[0].outputs[0].logprobs[i][token_ids_1[i]].decoded_token for i in range(seq_len_1)]\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(f\"Output 2 generated sequence :\\n{outputs2[0].outputs[0].text}\")  # noqa: T201\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"\"\"\\n**** Output 2 Tokens and Logprobs ****\\n\n",
    "\"\"\")  # noqa: T201\n",
    "\n",
    "for i in range(seq_len_2):\n",
    "    pprint(f\"Token ID: {token_ids_2[i]}, Decoded_token: {outputs2[0].outputs[0].logprobs[i][token_ids_2[i]].decoded_token}\")  # noqa: T201\n",
    "list_of_sampled_tokens_2 = [outputs2[0].outputs[0].logprobs[i][token_ids_2[i]].decoded_token for i in range(seq_len_2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc59c6a",
   "metadata": {},
   "source": [
    "### Instantiate the WEPR scorer\n",
    "\n",
    "First parse the output with the `parse_model_outputs` function.\n",
    "\n",
    "Then pass the logprobs directly to the `scorer.compute()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d6ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEPR Sequence Score for the first output: [0.22794435452266917]\n",
      "\n",
      "\n",
      "WEPR Token-level Scores for the first output: [array([0.11841268, 0.08238266, 0.07749902, 0.07747021, 0.08158927,\n",
      "       0.07747053, 0.0351684 , 0.11387737, 0.07800352], dtype=float32)]\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      "\n",
      "WEPR Sequence Score for the second output: [0.9678448302576981]\n",
      "\n",
      "\n",
      "WEPR Token-level Scores for the second output: [array([0.21733956, 0.18688072, 0.07805948, 0.07747021, 0.08485898,\n",
      "       0.07747161, 0.08701459, 0.08287204, 0.07750972, 0.07747956,\n",
      "       0.22602727, 0.0991644 , 0.7714013 , 0.08257567, 0.9991934 ,\n",
      "       0.46143848, 0.9989643 , 0.16862838, 0.09296815, 0.07872952,\n",
      "       0.07794683, 0.09680568, 0.8333083 , 0.07828344, 0.35632887,\n",
      "       0.10569014], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "scorer = WEPR(pretrained_model_name_or_path=MODEL_CHECKPOINT)\n",
    "\n",
    "processed_prompts_1 = parse_model_outputs(outputs1)\n",
    "wepr_scores_1 = scorer.compute(processed_prompts_1)\n",
    "print(f\"WEPR Sequence Score for the first output: {wepr_scores_1}\")  # noqa: T201\n",
    "print(\"\\n\")\n",
    "wepr_token_scores_1 = scorer.compute_token_scores(processed_prompts_1)\n",
    "print(f\"WEPR Token-level Scores for the first output: {wepr_token_scores_1}\")\n",
    "print(\"\\n\")\n",
    "print(\"*\"*40)\n",
    "print(\"\\n\")\n",
    "processed_prompts_2 = parse_model_outputs(outputs2)\n",
    "wepr_scores_2 = scorer.compute(processed_prompts_2)\n",
    "print(f\"WEPR Sequence Score for the second output: {wepr_scores_2}\")  # noqa: T201\n",
    "print(\"\\n\")\n",
    "\n",
    "wepr_token_scores_2 = scorer.compute_token_scores(processed_prompts_2)\n",
    "print(f\"WEPR Token-level Scores for the second output: {wepr_token_scores_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ade529",
   "metadata": {},
   "source": [
    "### Visualize the token probabilities\n",
    "\n",
    "We will use inline HTML coloring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfec93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(score):\n",
    "    # Using rgba for alpha transparency\n",
    "    if 0 <= score <= 0.35:\n",
    "        return \"rgba(0, 255, 0, 0.3)\"  # Green with low alpha\n",
    "    elif 0.35 < score <= 0.7:\n",
    "        return \"rgba(255, 255, 0, 0.3)\"  # Yellow with low alpha\n",
    "    else:\n",
    "        return \"rgba(255, 0, 0, 0.3)\"    # Red with low alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "83258fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEPR Sequence Score for the first output: [0.22794435452266917]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: monospace; font-size: 14px; line-height: 1.5;\"><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"><br></span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"><</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\">|</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\">assistant</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\">|></span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"><br></span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\">Paris</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\">.</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"><|endoftext|></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html_content = '<div style=\"font-family: monospace; font-size: 14px; line-height: 1.5;\">'\n",
    "for token, score in zip(list_of_sampled_tokens_1, wepr_token_scores_1[0]):\n",
    "    # Handle newlines for display purposes\n",
    "    display_token = token.replace('\\n', '<br>')\n",
    "    color = get_color(score)\n",
    "    html_content += f'<span style=\"background-color: {color}; padding: 2px; margin: 1px; border-radius: 3px;\">{display_token}</span>'\n",
    "\n",
    "html_content += '</div>'\n",
    "print(f\"WEPR Sequence Score for the first output: {wepr_scores_1}\") \n",
    "display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "430c41d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEPR Sequence Score for the second output: [0.9678448302576981]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: monospace; font-size: 14px; line-height: 1.5;\"><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"><br></span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"><</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\">|</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\">assistant</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\">|></span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"><br></span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\">Charles</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> Mos</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\">lon</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\">ka</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> is</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> a</span><span style=\"background-color: rgba(255, 0, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> South</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> African</span><span style=\"background-color: rgba(255, 0, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> writer</span><span style=\"background-color: rgba(255, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> and</span><span style=\"background-color: rgba(255, 0, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> journalist</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\">.</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> He</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> was</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> born</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> in</span><span style=\"background-color: rgba(255, 0, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> Cape</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"> Town</span><span style=\"background-color: rgba(255, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\">.</span><span style=\"background-color: rgba(0, 255, 0, 0.3); padding: 2px; margin: 1px; border-radius: 3px;\"><|endoftext|></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html_content = '<div style=\"font-family: monospace; font-size: 14px; line-height: 1.5;\">'\n",
    "for token, score in zip(list_of_sampled_tokens_2, wepr_token_scores_2[0]):\n",
    "    # Handle newlines for display purposes\n",
    "    display_token = token.replace('\\n', '<br>')\n",
    "    color = get_color(score)\n",
    "    html_content += f'<span style=\"background-color: {color}; padding: 2px; margin: 1px; border-radius: 3px;\">{display_token}</span>'\n",
    "\n",
    "html_content += '</div>'\n",
    "print(f\"WEPR Sequence Score for the second output: {wepr_scores_2}\") \n",
    "display(HTML(html_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artefactual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
